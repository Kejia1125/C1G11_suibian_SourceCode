# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JxpXuPeYxn__P6LTP5LBGoX-SoPYuB2J
"""

!pip install -q scikit-learn tensorflow==2.12.0 pandas matplotlib seaborn

import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

from google.colab import drive
drive.mount('/content/drive')

filename = "/content/drive/MyDrive/Colab Notebooks/datatraining.txt"

df = pd.read_csv(
    filename,
    header=0,
    names=["index", "timestamp", "Temperature", "Humidity", "Light", "CO2", "HumidityRatio", "Occupancy"],
    parse_dates=["timestamp"],
)

df = df.drop(columns=["index"])
df["Occupancy"] = df["Occupancy"].astype(int)
df = df.sort_values("timestamp").reset_index(drop=True)
df.head()

sensor_cols = ["Temperature", "Humidity", "Light", "CO2", "HumidityRatio"]

df['hour'] = df['timestamp'].dt.hour
df['minute'] = df['timestamp'].dt.minute
df['dayofweek'] = df['timestamp'].dt.dayofweek
df['is_weekend'] = df['dayofweek'].isin([5,6]).astype(int)

for c in sensor_cols:
    df[f'{c}_lag1'] = df[c].shift(1)
    df[f'{c}_roll5'] = df[c].rolling(window=5, min_periods=1).mean()

df = df.dropna().reset_index(drop=True)

# Occupancy fraction by hour
plt.figure(figsize=(8,4))
sns.barplot(x='hour', y='Occupancy', data=df.groupby('hour')['Occupancy'].mean().reset_index())
plt.ylabel('Fraction occupied')
plt.title('Occupancy fraction by hour')
plt.show()

# Sensor correlation with occupancy
plt.figure(figsize=(8,6))
sns.heatmap(df[sensor_cols + ['Occupancy']].corr(), annot=True, fmt=".2f")
plt.title('Sensor correlation with occupancy')
plt.show()

# 80% train, 20% test
split_idx = int(len(df)*0.8)
train_df = df.iloc[:split_idx].copy()
test_df = df.iloc[split_idx:].copy()

# Features
feature_cols = ['hour','dayofweek','is_weekend'] + sensor_cols + [f'{c}_lag1' for c in sensor_cols] + [f'{c}_roll5' for c in sensor_cols]

X_train = train_df[feature_cols].values
y_train = train_df['Occupancy'].values
X_test  = test_df[feature_cols].values
y_test  = test_df['Occupancy'].values

# Scale numeric features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train Random Forest
rf = RandomForestClassifier(n_estimators=150, max_depth=10, random_state=42, n_jobs=-1)
rf.fit(X_train, y_train)

# Predict and evaluate
y_pred = rf.predict(X_test)
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

# Feature importance
fi = pd.DataFrame({'feature': feature_cols, 'importance': rf.feature_importances_}).sort_values('importance', ascending=False)
fi.head(12)

# Prepare sequences for LSTM
seq_len = 30  # past 30 timesteps
forecast_horizon = 1  # predict next timestep

# Scale features
mms = MinMaxScaler()
df_scaled = df.copy()
df_scaled[feature_cols] = mms.fit_transform(df_scaled[feature_cols])

train_scaled = df_scaled.iloc[:split_idx]
test_scaled = df_scaled.iloc[split_idx:]

def make_sequences(df_input, features, seq_len, horizon):
    X, y = [], []
    vals = df_input[features].values
    labels = df_input['Occupancy'].values
    for i in range(len(df_input) - seq_len - horizon + 1):
        X.append(vals[i:i+seq_len])
        y.append(labels[i+seq_len+horizon-1])
    return np.array(X), np.array(y)

X_tr, y_tr = make_sequences(train_scaled, feature_cols, seq_len, forecast_horizon)
X_te, y_te = make_sequences(test_scaled, feature_cols, seq_len, forecast_horizon)

print("X_tr shape:", X_tr.shape, "y_tr shape:", y_tr.shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

model = Sequential([
    LSTM(64, input_shape=(X_tr.shape[1], X_tr.shape[2]), return_sequences=False),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')  # binary occupancy
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

history = model.fit(X_tr, y_tr, epochs=15, batch_size=64, validation_split=0.1, verbose=2)

y_de pred_prob = model.predict(X_te).ravel()
y_pred = (y_pred_prob >= 0.5).astype(int)

print("LSTM Accuracy:", accuracy_score(y_te, y_pred))
from sklearn.metrics import classification_report
print(classification_report(y_te, y_pred))

import joblib
# Random Forest
joblib.dump(rf, "/content/drive/MyDrive/occupancy_rf.pkl")
joblib.dump(scaler, "/content/drive/MyDrive/occupancy_scaler.pkl")
# LSTM
model.save("/content/drive/MyDrive/occupancy_lstm.h5")

# RF Confusion Matrix
cm = confusion_matrix(y_test, rf.predict(X_test))
sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('RF Confusion Matrix')
plt.show()

# LSTM Loss plot
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.legend(); plt.title('LSTM Loss'); plt.show()